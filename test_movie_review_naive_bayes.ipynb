{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#movie review sentiment code analysis\n",
    "import nltk.classify.util   #classification of positive and negative word\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import movie_reviews\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#this is how naive bayes classifier accepts the input\n",
    "def create_word_features(words):\n",
    "    words=[word for word in words if len(word)>2]\n",
    "    useful_words=[word for word in words if word not in stopwords.words(\"english\")]\n",
    "    my_dict=dict([(word, True) for word in useful_words])   # to get unique words \n",
    "    return my_dict\n",
    "\n",
    "#print create_word_features([\"the\",\"quick\",\"brown\",\"quick\",\"aa\"])\n",
    "\n",
    "neg_reviews=[]\n",
    "for fileid in movie_reviews.fileids('neg'):\n",
    "    words=movie_reviews.words(fileid)    #opening file\n",
    "    neg_reviews.append((create_word_features(words),\"negative\")) # classifier that this is a negative list \n",
    "    \n",
    "print(neg_reviews[0])\n",
    "print(len(neg_reviews))\n",
    "\n",
    "\n",
    "pos_reviews=[]\n",
    "for fileid in movie_reviews.fileids('pos'):\n",
    "    words=movie_reviews.words(fileid)    #opening file\n",
    "    pos_reviews.append((create_word_features(words),\"positive\")) # classifier that this is a negative list \n",
    "    \n",
    "print(pos_reviews[0])\n",
    "print(len(pos_reviews))\n",
    "\n",
    "\n",
    "train_set=neg_reviews[:750]+pos_reviews[:750]\n",
    "test_set=neg_reviews[750:]+pos_reviews[750:]\n",
    "print(len(train_set),len(test_set))\n",
    "\n",
    "classifier=NaiveBayesClassifier.train(train_set)\n",
    "accuracy =nltk.classify.util.accuracy(classifier,test_set)\n",
    "print (accuracy*100)\n",
    "\n",
    "review_test=\"\"\"good movie . Do watch  \"\"\"\n",
    "print review_test\n",
    "\n",
    "words=word_tokenize(review_test)\n",
    "words=create_word_features(words)  #words is a dictionary\n",
    "type(train_set)\n",
    "type(words)\n",
    "print words\n",
    "\n",
    "print \"res=\",classifier.classify(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
