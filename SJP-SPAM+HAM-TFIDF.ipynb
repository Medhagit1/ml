{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMSSpamCollection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Status                                           Messages\n",
      "0    ham  Go until jurong point, crazy.. Available only ...\n",
      "1    ham                      Ok lar... Joking wif u oni...\n",
      "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3    ham  U dun say so early hor... U c already then say...\n",
      "4    ham  Nah I don't think he goes to usf, he lives aro...\n",
      "(5572, 2)\n",
      "yohhhhooooooooooo we have a lot of data to classify spam or hamm  Is it a similar problem for email classification ?!\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('SMSSpamCollection',sep='\\t',names=['Status','Messages'])\n",
    "print(df.head())\n",
    "print(df.shape)\n",
    "print(\"yohhhhooooooooooo we have a lot of data to classify spam or hamm  Is it a similar problem for email classification ?!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "these are spams emails 747\n",
      "these are ham mails = 4825\n"
     ]
    }
   ],
   "source": [
    "print(\"these are spams emails\",len(df[df.Status=='spam']))\n",
    "print(\"these are ham mails =\",len(df[df.Status=='ham']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Status                                           Messages\n",
      "0      0  Go until jurong point, crazy.. Available only ...\n",
      "1      0                      Ok lar... Joking wif u oni...\n",
      "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      0  U dun say so early hor... U c already then say...\n",
      "4      0  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# In this function we have replaced the spam amd ham by 0 and 1 as labels :::\n",
    "df.loc[df[\"Status\"]=='spam','Status']='1'\n",
    "df.loc[df[\"Status\"]=='ham','Status']='0'\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HERE IS YOUR DATASET \n",
      " 0       Go until jurong point, crazy.. Available only ...\n",
      "1                           Ok lar... Joking wif u oni...\n",
      "2       Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3       U dun say so early hor... U c already then say...\n",
      "4       Nah I don't think he goes to usf, he lives aro...\n",
      "5       FreeMsg Hey there darling it's been 3 week's n...\n",
      "6       Even my brother is not like to speak with me. ...\n",
      "7       As per your request 'Melle Melle (Oru Minnamin...\n",
      "8       WINNER!! As a valued network customer you have...\n",
      "9       Had your mobile 11 months or more? U R entitle...\n",
      "10      I'm gonna be home soon and i don't want to tal...\n",
      "11      SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12      URGENT! You have won a 1 week FREE membership ...\n",
      "13      I've been searching for the right words to tha...\n",
      "14                    I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15      XXXMobileMovieClub: To use your credit, click ...\n",
      "16                             Oh k...i'm watching here:)\n",
      "17      Eh u remember how 2 spell his name... Yes i di...\n",
      "18      Fine if thats the way u feel. Thats the way ...\n",
      "19      England v Macedonia - dont miss the goals/team...\n",
      "20              Is that seriously how you spell his name?\n",
      "21        I‘m going to try for 2 months ha ha only joking\n",
      "22      So ü pay first lar... Then when is da stock co...\n",
      "23      Aft i finish my lunch then i go str down lor. ...\n",
      "24      Ffffffffff. Alright no way I can meet up with ...\n",
      "25      Just forced myself to eat a slice. I'm really ...\n",
      "26                         Lol your always so convincing.\n",
      "27      Did you catch the bus ? Are you frying an egg ...\n",
      "28      I'm back &amp; we're packing the car now, I'll...\n",
      "29      Ahhh. Work. I vaguely remember that! What does...\n",
      "                              ...                        \n",
      "5542             Armand says get your ass over to epsilon\n",
      "5543               U still havent got urself a jacket ah?\n",
      "5544    I'm taking derek &amp; taylor to walmart, if I...\n",
      "5545        Hi its in durban are you still on this number\n",
      "5546           Ic. There are a lotta childporn cars then.\n",
      "5547    Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5548                   No, I was trying it all weekend ;V\n",
      "5549    You know, wot people wear. T shirts, jumpers, ...\n",
      "5550          Cool, what time you think you can get here?\n",
      "5551    Wen did you get so spiritual and deep. That's ...\n",
      "5552    Have a safe trip to Nigeria. Wish you happines...\n",
      "5553                          Hahaha..use your brain dear\n",
      "5554    Well keep in mind I've only got enough gas for...\n",
      "5555    Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5556    Yes i have. So that's why u texted. Pshew...mi...\n",
      "5557    No. I meant the calculation is the same. That ...\n",
      "5558                               Sorry, I'll call later\n",
      "5559    if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5560                    Anything lor. Juz both of us lor.\n",
      "5561    Get me out of this dump heap. My mom decided t...\n",
      "5562    Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5563                                  Ard 6 like dat lor.\n",
      "5564    Why don't you wait 'til at least wednesday to ...\n",
      "5565                                         Huh y lei...\n",
      "5566    REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567    This is the 2nd time we have tried 2 contact u...\n",
      "5568                 Will ü b going to esplanade fr home?\n",
      "5569    Pity, * was in mood for that. So...any other s...\n",
      "5570    The guy did some bitching but I acted like i'd...\n",
      "5571                           Rofl. Its true to its name\n",
      "Name: Messages, Length: 5572, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_y=df[\"Status\"]\n",
    "df_x=df[\"Messages\"]\n",
    "print(\"HERE IS YOUR DATASET \\n\",df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=TfidfVectorizer(min_df=1,stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2,random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.        , 0.        , 0.70710678, 0.        ,\n",
       "        0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.57735027, 0.        , 0.        ,\n",
       "        0.57735027, 0.57735027],\n",
       "       [0.        , 0.70710678, 0.        , 0.        , 0.70710678,\n",
       "        0.        , 0.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_trains=cv.fit_transform([\"Hi how are you, you are the best ?\",\"hey what's new today\",\"lucky draw are\"])\n",
    "x_trains.toarray()\n",
    "\n",
    "\n",
    "# this tfidf vectorizer helps u sto find the distribution of words in the whole docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['hi', 'best'], dtype='<U5')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.inverse_transform(x_trains[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best', 'draw', 'hey', 'hi', 'lucky', 'new', 'today']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()  # features are the words in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best', 'draw', 'hey', 'hi', 'lucky', 'new', 'today']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()  # features are the words in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = TfidfVectorizer(min_df=1,stop_words='english')\n",
    "# initialise a new count vectorizer above was just an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincv=cv1.fit_transform(x_train)\n",
    "x_testcv=cv1.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=x_traincv.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.19618715, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['checking', 'going', 'got', 'haha', 'lor', 'mails', 'online',\n",
       "        'replying', 'sleeping', 'spys', 'wat'], dtype='<U27')]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv1.inverse_transform(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb=MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_train))\n",
    "y_train=y_train.astype('int') # they were may be str type we need to make them as int type\n",
    "print(type(y_train))\n",
    "mnb.fit(x_traincv,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "pred=mnb.predict(x_testcv)    # what is diff. btwn fit and fit transform\n",
    "print(pred)\n",
    "print(type(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 1]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "actual = np.array(y_test)\n",
    "actual= actual.astype('int')\n",
    "print(actual)\n",
    "print(type(actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95.7847533632287 %\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(actual, pred)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[946   1]\n",
      " [ 46 122]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(actual, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
